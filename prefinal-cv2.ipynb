{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7204247,"sourceType":"datasetVersion","datasetId":4167694}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport time\nimport random\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\ndef count_images_in_folders(directory):\n    folder_counts = {}\n\n    for folder_name in os.listdir(directory):\n        folder_path = os.path.join(directory, folder_name)\n\n        if os.path.isdir(folder_path):\n            # Count the number of files in the folder\n            num_files = len([file for file in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, file))])\n            folder_counts[folder_name] = num_files\n\n    return folder_counts\n\ntrain_dir = \"/kaggle/input/reco-part2/Product Recoginition/Training Data\"\nval_dir = \"/kaggle/input/reco-part2/Product Recoginition/Validation Data\"\n\ntrain_dict = count_images_in_folders(train_dir)\nval_dict = count_images_in_folders(val_dir)\n\nprint(\"Train Dictionary:\",train_dict)\n\nprint(\"Validation Dictionary:\",val_dict)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# triples","metadata":{}},{"cell_type":"code","source":"import os\nimport random\n\ndef create_triplets(directory, folder_list, max_files=10, file_extension=\".png\"):\n    triplets = []\n    folders = list(folder_list.keys())\n    \n    for folder in folders:\n        path = os.path.join(directory, folder)\n        files = [f for f in os.listdir(path) if f.endswith(file_extension)][:max_files]\n        num_files = len(files)\n        \n        for i in range(num_files-1):\n            for j in range(i+1, num_files):\n                anchor = (folder, f\"{files[i]}\")\n                positive = (folder, f\"{files[j]}\")\n\n                neg_folder = folder\n                while neg_folder == folder:\n                    neg_folder = random.choice(folders)\n                neg_files = [f for f in os.listdir(os.path.join(directory, neg_folder)) if f.endswith(file_extension)]\n                neg_file = random.choice(neg_files)\n                negative = (neg_folder, f\"{neg_file}\")\n\n                triplets.append((anchor, positive, negative))\n            \n    random.shuffle(triplets)\n    return triplets\n\n# Assuming train_dir, train_dict, val_dir, and val_dict are defined\ntrain_triplet = create_triplets(train_dir, train_dict)\ntest_triplet = create_triplets(val_dir, val_dict)\n\nprint(\"Number of training triplets:\", len(train_triplet))\nprint(\"Number of testing triplets:\", len(test_triplet))\n\nprint(\"\\nExamples of triplets:\")\nfor i in range(5):\n    print(train_triplet[i])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"def read_image2(index):\n    path = os.path.join(train_dir, index[0], \"web\"+str(int(index[1][0])+1)\n#                         + index[1][1:]\n                       +\".png\")\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# batch generator","metadata":{}},{"cell_type":"code","source":"################for train \nimport cv2\nimport os\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\n\n\nROOT    = \"/kaggle/input/reco-part2/Product Recoginition/Training Data\"\n#val_dir = \"/kaggle/input/reco-part2/Product Recoginition/Validation Data\"\n\n\ndef read_image(index , target_size=(224, 224)):\n    path  = os.path.join(ROOT, index[0], index[1])\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, target_size)  # Resize the image\n    return image\n\ndef get_batch(triplet_list, batch_size=256, preprocess=True):\n    batch_steps = len(triplet_list)//batch_size\n    \n    for i in range(batch_steps + 1):\n        anchor   = []\n        positive = []\n        negative = []\n        \n        j = i * batch_size\n        while j < (i + 1) * batch_size and j < len(triplet_list):\n            a, p, n = triplet_list[j]\n            anchor_img   = read_image(a)\n            positive_img = read_image(p)\n            negative_img = read_image(n)\n            \n            if anchor_img is not None and positive_img is not None and negative_img is not None:\n                anchor.append(anchor_img)\n                positive.append(positive_img)\n                negative.append(negative_img)\n            \n            j += 1\n            \n        anchor   = np.array(anchor)\n        positive = np.array(positive)\n        negative = np.array(negative)\n        \n        if preprocess:\n            anchor   = preprocess_input(anchor)\n            positive = preprocess_input(positive)\n            negative = preprocess_input(negative)\n        \n        yield ([anchor, positive, negative])\n\nnum_plots = 3\n\nf, axes = plt.subplots(num_plots, 3, figsize=(15, 20))\n\nfor x in get_batch(train_triplet, batch_size=num_plots, preprocess=False):\n    a, p, n = x\n    for i in range(num_plots):\n        axes[i, 0].imshow(a[i])\n        axes[i, 1].imshow(p[i])\n        axes[i, 2].imshow(n[i])\n        i += 1\n    break\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################for test \n\nimport cv2\nimport os\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\n\n\nroot = \"/kaggle/input/reco-part2/Product Recoginition/Validation Data\"\n\n\ndef read_image1(index , target_size=(224, 224)):\n    path  = os.path.join(root, index[0], index[1])\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, target_size)  # Resize the image\n    return image\n\ndef get_batch_test(triplet_list, batch_size=256, preprocess=True):\n    batch_steps = len(triplet_list)//batch_size\n    \n    for i in range(batch_steps + 1):\n        anchor   = []\n        positive = []\n        negative = []\n        \n        j = i * batch_size\n        while j < (i + 1) * batch_size and j < len(triplet_list):\n            a, p, n = triplet_list[j]\n            anchor_img   = read_image1(a)\n            positive_img = read_image1(p)\n            negative_img = read_image1(n)\n            \n            if anchor_img is not None and positive_img is not None and negative_img is not None:\n                anchor.append(anchor_img)\n                positive.append(positive_img)\n                negative.append(negative_img)\n            \n            j += 1\n            \n        anchor   = np.array(anchor)\n        positive = np.array(positive)\n        negative = np.array(negative)\n        \n        if preprocess:\n            anchor   = preprocess_input(anchor)\n            positive = preprocess_input(positive)\n            negative = preprocess_input(negative)\n        \n        yield ([anchor, positive, negative])\n\nnum_plots = 3\n\nf, axes = plt.subplots(num_plots, 3, figsize=(15, 20))\n\nfor x in get_batch_test(test_triplet, batch_size=num_plots, preprocess=False):\n    a, p, n = x\n    for i in range(num_plots):\n        axes[i, 0].imshow(a[i])\n        axes[i, 1].imshow(p[i])\n        axes[i, 2].imshow(n[i])\n        i += 1\n    break\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# #create model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import backend, layers, metrics\n\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import Xception\nfrom tensorflow.keras.models import Model, Sequential\n\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_encoder(input_shape):\n    \"\"\" Returns the image encoding model \"\"\"\n\n    pretrained_model = Xception(\n        input_shape=input_shape,\n        weights='imagenet',\n        include_top=False,\n        pooling='avg',\n    )\n    \n    for i in range(len(pretrained_model.layers)-27):\n        pretrained_model.layers[i].trainable = False\n\n    encode_model = Sequential([\n        pretrained_model,\n        layers.Flatten(),\n        layers.Dense(512, activation='relu'),\n        layers.BatchNormalization(),\n        layers.Dense(256, activation=\"relu\"),\n        layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))\n    ], name=\"Encode_Model\")\n    return encode_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DistanceLayer(layers.Layer):\n    # A layer to compute ‖f(A) - f(P)‖² and ‖f(A) - f(N)‖²\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    def call(self, anchor, positive, negative):\n        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n        return (ap_distance, an_distance)\n    \n\ndef get_siamese_network(input_shape = (224, 224, 3)):\n    encoder = get_encoder(input_shape)\n    \n    # Input Layers for the images\n    anchor_input   = layers.Input(input_shape, name=\"Anchor_Input\")\n    positive_input = layers.Input(input_shape, name=\"Positive_Input\")\n    negative_input = layers.Input(input_shape, name=\"Negative_Input\")\n    \n    ## Generate the encodings (feature vectors) for the images\n    encoded_a = encoder(anchor_input)\n    encoded_p = encoder(positive_input)\n    encoded_n = encoder(negative_input)\n    \n    # A layer to compute ‖f(A) - f(P)‖² and ‖f(A) - f(N)‖²\n    distances = DistanceLayer()(\n        encoder(anchor_input),\n        encoder(positive_input),\n        encoder(negative_input)\n    )\n    \n    # Creating the Model\n    siamese_network = Model(\n        inputs  = [anchor_input, positive_input, negative_input],\n        outputs = distances,\n        name = \"Siamese_Network\"\n    )\n    return siamese_network\n\nsiamese_network = get_siamese_network()\nsiamese_network.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(siamese_network, show_shapes=True, show_layer_names=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SiameseModel(Model):\n    # Builds a Siamese model based on a base-model\n    def __init__(self, siamese_network, margin=1.0):\n        super(SiameseModel, self).__init__()\n        \n        self.margin = margin\n        self.siamese_network = siamese_network\n        self.loss_tracker = metrics.Mean(name=\"loss\")\n\n    def call(self, inputs):\n        return self.siamese_network(inputs)\n\n    def train_step(self, data):\n        # GradientTape get the gradients when we compute loss, and uses them to update the weights\n        with tf.GradientTape() as tape:\n            loss = self._compute_loss(data)\n            \n        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n        self.optimizer.apply_gradients(zip(gradients, self.siamese_network.trainable_weights))\n        \n        self.loss_tracker.update_state(loss)\n        return {\"loss\": self.loss_tracker.result()}\n\n    def test_step(self, data):\n        loss = self._compute_loss(data)\n        \n        self.loss_tracker.update_state(loss)\n        return {\"loss\": self.loss_tracker.result()}\n\n    def _compute_loss(self, data):\n        # Get the two distances from the network, then compute the triplet loss\n        ap_distance, an_distance = self.siamese_network(data)\n        loss = tf.maximum(ap_distance - an_distance + self.margin, 0.0)\n        return loss\n\n    @property\n    def metrics(self):\n        # We need to list our metrics so the reset_states() can be called automatically.\n        return [self.loss_tracker]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"siamese_model = SiameseModel(siamese_network)\n\noptimizer = Adam(learning_rate=1e-3, epsilon=1e-01)\nsiamese_model.compile(optimizer=optimizer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_on_triplets(batch_size = 256):\n    pos_scores, neg_scores = [], []\n\n    for data in get_batch_test(test_triplet, batch_size=batch_size):\n        prediction = siamese_model.predict(data)\n        pos_scores += list(prediction[0])\n        neg_scores += list(prediction[1])\n    \n    accuracy = np.sum(np.array(pos_scores) < np.array(neg_scores)) / len(pos_scores)\n    ap_mean = np.mean(pos_scores)\n    an_mean = np.mean(neg_scores)\n    ap_stds = np.std(pos_scores)\n    an_stds = np.std(neg_scores)\n    \n    print(f\"Accuracy on test = {accuracy:.5f}\")\n    return (accuracy, ap_mean, an_mean, ap_stds, an_stds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\n\n# Suppress libpng warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning, module=\"PIL.PngImagePlugin\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"save_all = False\nepochs = 30\nbatch_size = 128\n\nmax_acc = 0\ntrain_loss = []\ntest_metrics = []\n\nfor epoch in range(1, epochs+1):\n    t = time.time()\n    \n    # Training the model on train data\n    epoch_loss = []\n    \n    for data in get_batch(train_triplet, batch_size=batch_size):\n        loss = siamese_model.train_on_batch(data)\n        epoch_loss.append(loss)\n    epoch_loss = sum(epoch_loss)/len(epoch_loss)\n    train_loss.append(epoch_loss)\n\n    print(f\"\\nEPOCH: {epoch} \\t (Epoch done in {int(time.time()-t)} sec)\")\n    print(f\"Loss on train    = {epoch_loss:.5f}\")\n    \n    # Testing the model on test data\n    metric = test_on_triplets(batch_size=batch_size)\n    test_metrics.append(metric)\n    accuracy = metric[0]\n    \n    # Saving the model weights\n    if save_all or accuracy>=max_acc:\n        siamese_model.save_weights(\"siamese_model\")\n        max_acc = accuracy\n\n# Saving the model after all epochs run\nsiamese_model.save_weights(\"siamese_model-final\")\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_all = False\nepochs = 3\nbatch_size = 128\n\nmax_acc = 0\ntrain_loss = []\ntest_metrics = []\n\nstart_time_training = time.time()\n\nfor epoch in range(1, epochs+1):\n    t = time.time()\n    \n    # Training the model on train data\n    epoch_loss = []\n    \n    for data in get_batch(train_triplet, batch_size=batch_size):\n        loss = siamese_model.train_on_batch(data)\n        epoch_loss.append(loss)\n    epoch_loss = sum(epoch_loss)/len(epoch_loss)\n    train_loss.append(epoch_loss)\n\n    print(f\"\\nEPOCH: {epoch} \\t (Epoch done in {int(time.time()-t)} sec)\")\n    print(f\"Loss on train    = {epoch_loss:.5f}\")\n    \n    # Testing the model on test data\n    start_time_testing = time.time()\n    \n    metric = test_on_triplets(batch_size=batch_size)\n    test_metrics.append(metric)\n    accuracy = metric[0]\n    \n    end_time_testing = time.time()\n    total_time_testing = end_time_testing - start_time_testing\n\n    # Saving the model weights\n    if save_all or accuracy>=max_acc:\n        siamese_model.save_weights(\"siamese_model_weights.h5\")\n        max_acc = accuracy\n\n        \nend_time_training = time.time()\ntotal_time_training = end_time_training - start_time_training\n\n\n# Saving the model after all epochs run\nsiamese_model.save(\"siamese_model_final\", save_format=\"tf\")\n\n\nprint(f\"\\nTotal Training Time: {total_time_training} seconds\")\n\nprint(f\"Total Testing Time: {total_time_testing} seconds\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_metrics(loss, metrics):\n    # Extracting individual metrics from metrics\n    accuracy = metrics[:, 0]\n    ap_mean  = metrics[:, 1]\n    an_mean  = metrics[:, 2]\n    ap_stds  = metrics[:, 3]\n    an_stds  = metrics[:, 4]\n    \n    plt.figure(figsize=(15,5))\n    \n    # Plotting the loss over epochs\n    plt.subplot(121)\n    plt.plot(loss, 'b', label='Loss')\n    plt.title('Training loss')\n    plt.legend()\n    \n    # Plotting the accuracy over epochs\n    plt.subplot(122)\n    plt.plot(accuracy, 'r', label='Accuracy')\n    plt.title('Testing Accuracy')\n    plt.legend()\n    \n    plt.figure(figsize=(15,5))\n    \n    # Comparing the Means over epochs\n    plt.subplot(121)\n    plt.plot(ap_mean, 'b', label='AP Mean')\n    plt.plot(an_mean, 'g', label='AN Mean')\n    plt.title('Means Comparision')\n    plt.legend()\n    \n    # Plotting the accuracy\n    ap_75quartile = (ap_mean+ap_stds)\n    an_75quartile = (an_mean-an_stds)\n    plt.subplot(122)\n    plt.plot(ap_75quartile, 'b', label='AP (Mean+SD)')\n    plt.plot(an_75quartile, 'g', label='AN (Mean-SD)')\n    plt.title('75th Quartile Comparision')\n    plt.legend()\n\ntest_metrics = np.array(test_metrics)\nplot_metrics(train_loss, test_metrics)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_encoder(model):\n    encoder = get_encoder((224, 224, 3))\n    i=0\n    for e_layer in model.layers[0].layers[3].layers:\n        layer_weight = e_layer.get_weights()\n        encoder.layers[i].set_weights(layer_weight)\n        i+=1\n    return encoder\n\nencoder = extract_encoder(siamese_model)\nencoder.save_weights(\"encoder\")\nencoder.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def classify_images(face_list1, face_list2, threshold=1.3):\n    # Getting the encodings for the passed faces\n    tensor1 = encoder.predict(face_list1)\n    tensor2 = encoder.predict(face_list2)\n    \n    distance = np.sum(np.square(tensor1-tensor2), axis=-1)\n    prediction = np.where(distance<=threshold, 0, 1)\n    return prediction","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ModelMetrics(pos_list, neg_list):\n    true = np.array([0]*len(pos_list)+[1]*len(neg_list))\n    pred = np.append(pos_list, neg_list)\n    \n    # Compute and print the accuracy\n    print(f\"\\nAccuracy of model: {accuracy_score(true, pred)}\\n\")\n    \n    # Compute and plot the Confusion matrix\n    cf_matrix = confusion_matrix(true, pred)\n\n    categories  = ['Similar','Different']\n    names = ['True Similar','False Similar', 'False Different','True Different']\n    percentages = ['{0:.2%}'.format(value) for value in cf_matrix.flatten() / np.sum(cf_matrix)]\n\n    labels = [f'{v1}\\n{v2}' for v1, v2 in zip(names, percentages)]\n    labels = np.asarray(labels).reshape(2,2)\n\n    sns.heatmap(cf_matrix, annot = labels, cmap = 'Blues',fmt = '',\n                xticklabels = categories, yticklabels = categories)\n\n    plt.xlabel(\"Predicted\", fontdict = {'size':14}, labelpad = 10)\n    plt.ylabel(\"Actual\"   , fontdict = {'size':14}, labelpad = 10)\n    plt.title (\"Confusion Matrix\", fontdict = {'size':18}, pad = 20)\n\n\npos_list = np.array([])\nneg_list = np.array([])\n\nfor data in get_batch_test(test_triplet, batch_size=256):\n    a, p, n = data\n    pos_list = np.append(pos_list, classify_images(a, p))\n    neg_list = np.append(neg_list, classify_images(a, n))\n    break\n\nModelMetrics(pos_list, neg_list)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaded_siamese_model = tf.keras.models.load_model(\"siamese_model_final\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaded_siamese_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}